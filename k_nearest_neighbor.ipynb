{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data\n",
    "- Data can be found here: https://archive.ics.uci.edu/ml/datasets/QSAR+fish+toxicity\n",
    "- the features are 6 molecular descriptors, the target is acute aquatic toxicity (that may kill fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.260</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.676</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.453</td>\n",
       "      <td>3.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.189</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.125</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.027</td>\n",
       "      <td>0.331</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.807</td>\n",
       "      <td>3.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.094</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.886</td>\n",
       "      <td>5.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1     X2     X3  X4  X5     X6      Y\n",
       "0  3.260  0.829  1.676   0   1  1.453  3.770\n",
       "1  2.189  0.580  0.863   0   0  1.348  3.115\n",
       "2  2.125  0.638  0.831   0   0  1.348  3.531\n",
       "3  3.027  0.331  1.472   1   0  1.807  3.510\n",
       "4  2.094  0.827  0.860   0   0  1.886  5.390"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['X1','X2','X3','X4','X5','X6','Y']\n",
    "data=pd.read_csv('qsar_fish_toxicity.csv',sep=';',names=columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "target='Y'\n",
    "features=data.columns.drop(labels='Y')\n",
    "i_test=random.sample(range(0,908),190)\n",
    "i_train=[]\n",
    "for i in data.index:\n",
    "    if i not in i_test:\n",
    "        i_train.append(i)\n",
    "X_train=data.loc[i_train,features]\n",
    "X_test=data.loc[i_test,features]\n",
    "y_train=data.loc[i_train,target]\n",
    "y_test=data.loc[i_test,target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean=np.mean(X_train)\n",
    "std=np.std(X_train)\n",
    "X_train-=mean\n",
    "X_test-=mean\n",
    "X_train/=std\n",
    "X_test/=std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making y categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.round(y_train)\n",
    "y_test=np.round(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting bais term and turning data in Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.insert(0,'bias',1)\n",
    "X_test.insert(0,'bias',1)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array([y_train]).T\n",
    "y_test=np.array([y_test]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "$d(q,p)=\\sqrt{\\sum_{i=1}^{n}(q_{i}-p_{i})^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN, K=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.72105263157895"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_predict=[]\n",
    "for test in X_test:\n",
    "    eu_dist=[]\n",
    "    for train in X_train:\n",
    "        eu_dist.append(np.sqrt(np.sum(train-test)**2))\n",
    "    idx=np.argsort(eu_dist)[:11]\n",
    "    most_common=Counter(y_train[idx].ravel()).most_common(1)\n",
    "    my_predict.append(most_common[0][0])\n",
    "my_acc=np.sum(my_predict==y_test)/len(y_test)\n",
    "my_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y_train.ravel()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN=KNeighborsClassifier(n_neighbors=11,metric='euclidean')\n",
    "KNN.fit(X_train,y)\n",
    "sk_predict=KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my accuracy score: 45.7211\n",
      "sklearn accuracy score: 42.1\n"
     ]
    }
   ],
   "source": [
    "my_acc=np.sum(my_predict==y_test)/len(y_test)\n",
    "sk_acc=np.sum(sk_predict==y_test)/len(y_test)\n",
    "print('my accuracy score:', np.round(my_acc,4))\n",
    "print('sklearn accuracy score:', np.round(sk_acc,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
